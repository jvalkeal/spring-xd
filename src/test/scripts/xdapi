#!/bin/bash

XD_HOST='http://localhost'
XD_PORT=9393
XDURL="$XD_HOST:$XD_PORT"

xdc() {
  curl -s -S -H "Accept: application/json" $@
}

# This is needed because the CI agents don't have an up-to-date version of curl which
# supports the --data-urlencode parameter
urlencode() {
  python -c "import sys, urllib as ul; print ul.quote_plus(sys.argv[1])" "$@"
}

create_stream() {
  local udef=`urlencode "$2"`
  echo "Creating stream $1 with definition '$udef' ..."
  xdc -d name=$1 -d "definition=$udef" -d deploy=${3:-'true'} "$XDURL/streams"
  echo -e '\n'
}

undeploy_stream() {
  xdc -X PUT -d deploy=false "$XDURL/streams/$1"
}

deploy_stream() {
  xdc -X PUT -d 'deploy=true' "$XDURL/streams/$1"
}

destroy_stream() {
  echo -e "Destroying stream $1 ..."
  xdc -X DELETE "$XDURL/streams/$1"
  echo -e '\n'
}

create_job() {
  local udef=`urlencode "$2"`
  echo -e "Creating job $1 with definition '$udef' ..."
  xdc -d name=$1 -d "definition=$udef" "$XDURL/jobs"
  echo -e '\n'
}

launch_job() {
  echo "Launching job $1 ..."
  xdc -X PUT "$XDURL/jobs/$1/launch"
  echo -e '\n'
}

destroy_job() {
  echo -e "Destroying job $1 ..."
  xdc -X DELETE "$XDURL/jobs/$1"
  echo -e '\n'
}

list_streams() {
  xdc -s $XDURL/streams #| python -m json.tool
  echo -e '\n'
}

list_jobs() {
  xdc -s $XDURL/jobs #| python -m json.tool
  echo -e '\n'
}

hdfs_size() {
  local hd_size=`hadoop fs -ls $1 | grep csv | awk '{a+=$5}; END{print a}'`
  echo "$hd_size"
}

assert_equals() {
  if [[ $1 != $2 ]]
  then
    echo "Expected $1 does not match actual value ($2)"
    exit 1;
  fi
}

wait_for_server() {
  i=6

  while [ $i != 0 ]
  do
      curl -s $XDURL
      if [ $? != 0 ]
      then
        echo "Waiting for server to start..."; sleep 10
        ((i--))
      else
        i=0
      fi
  done

  curl -s $XDURL

  if [ $? != 0 ]
  then
      echo -e "\n\n**** Server not started, exiting.\n\n"; exit 1
  else
      echo -e "\n\n**** Server is up...\n\n"
  fi
}

